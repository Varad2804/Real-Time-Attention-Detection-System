{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.utils import to_categorical\nimport joblib  # For saving scaler\n\n# Load the dataset (replace with your file path)\ndf = pd.read_csv('/kaggle/input/attention-detection-sys/attention_detection_dataset_v1.csv')\n\n\n# Show the cleaned dataset columns and first few rows\nprint(df.columns)\nprint(df.head())\n\n# Step 1: Data Cleaning\n# Drop rows or columns with missing values or handle them as needed\ndf.dropna(inplace=True)\n\n# Define the fixed mapping for the 'pose' column (target variable)\nlabel_mapping = {'forward': 0, 'down': 1, 'left': 2, 'right': 3}\n\n# Step 2: Apply the label mapping to the \"pose\" column\ndf[\"pose\"] = df[\"pose\"].map(label_mapping)\n\n# Check if any values are NaN after the mapping (you can drop or handle them as needed)\n#df.dropna(subset=[\"pose\"], inplace=True)\n\n# Step 3: Separate features (X) and the target variable (y)\n# Assuming the last column is the target variable (pose)\nX = df.iloc[:, :-1]  # All columns except the last one (features)\ny = df[\"label\"]  \n\n\n# Step 5: Normalize the data\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Save the scaler for future use during inference\njoblib.dump(scaler, '/kaggle/working/scaler.pkl')\n\n# Step 6: Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\nnum_classes=2\n\n# Step 7: Build a Neural Network Model\nmodel = Sequential()\nmodel.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))  # Input layer\nmodel.add(Dense(64, activation='relu'))  # Hidden layer 1\nmodel.add(Dense(32, activation='relu'))  # Hidden layer 2\nmodel.add(Dense(num_classes, activation='softmax'))  # Output layer (for multi-class classification)\n\n# Step 8: Compile the Model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# One-hot encode the labels\ny_train = to_categorical(y_train, num_classes=num_classes)\ny_test = to_categorical(y_test, num_classes=num_classes)\n\n\n# Step 9: Train the Model\nhistory = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=2)\n\n# Step 10: Evaluate the model on test data\ntest_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\nprint(f\"Test accuracy: {test_accuracy}\")\n\n# Step 11: Make predictions and evaluate the model using classification_report\ny_pred = model.predict(X_test)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_test_classes = np.argmax(y_test, axis=1)\n\n# Print classification report\nprint(classification_report(y_test_classes, y_pred_classes))\n\n# Step 12: Save model weights to a file in Kaggle's working directory\nweights_file = '/kaggle/working/model3.weights.h5'\nmodel.save_weights(weights_file)\nprint(f\"Model weights saved to '{weights_file}'\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport joblib  # To load the scaler and model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\n# Define the fixed mapping for categorical variables (same as during training)\nlabel_mapping = {'forward': 0, 'down': 1, 'left': 2, 'right': 3}\n\n# Load the pre-trained model weights and scaler\nscaler = joblib.load('/kaggle/working/scaler.pkl')\nweights_file = '/kaggle/working/model3.weights.h5'\n\n# Step 1: Define the same model architecture as during training\n# Ensure the input shape matches the shape used during training\nmodel = Sequential()\nmodel.add(Dense(128, activation='relu', input_shape=(16,)))  # Input layer (adjust 10 to match number of features)\nmodel.add(Dense(64, activation='relu'))  # Hidden layer 1\nmodel.add(Dense(32, activation='relu'))  # Hidden layer 2\nmodel.add(Dense(2, activation='softmax'))  # Output layer with 4 classes (for 'forward', 'down', 'left', 'right')\n\n# Load the trained model weights\nmodel.load_weights(weights_file)\n\n# Step 2: Example input data (replace this with the actual input data you want to predict)\n# In the example, the categorical \"down\" at index 7 needs to be mapped\nsample_input = [1,252.9670143,137.8716588,163.1315422,163.1269741,86.70405746,0,\"down\",-15,10,0,0,0,0,0,0]\n\n# Step 3: Apply the label mapping to the categorical column (index 7)\nsample_input[7] = label_mapping[sample_input[7]]  # 'down' -> 1\n\n# Step 4: Preprocess the input data\n# Reshape the input sample to be 2D (1 sample, n features) and scale it\nsample_input_scaled = scaler.transform(np.array(sample_input).reshape(1, -1))  # Scaling the input\n\n# Step 5: Make predictions\npredictions = model.predict(sample_input_scaled)\npredicted_class = np.argmax(predictions, axis=1)  # Get the class with the highest probability\n\n# # Step 6: Convert the predicted class back to the corresponding label\n# predicted_label = list(label_mapping.keys())[list(label_mapping.values()).index(predicted_class[0])]\n\n# Step 7: Print the predicted class\nprint(f\"Predicted class: {predicted_class}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T17:15:10.019240Z","iopub.status.idle":"2024-11-27T17:15:10.019791Z","shell.execute_reply.started":"2024-11-27T17:15:10.019559Z","shell.execute_reply":"2024-11-27T17:15:10.019581Z"}},"outputs":[],"execution_count":null}]}